{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e77df568",
   "metadata": {},
   "source": [
    "compte le nombre d'image que j'ai pour le glaucome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efec5b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAPPORT GLAUCOME (structure-based)\n",
      "\n",
      "ACRIMA          | glaucome:  396 | normal:  309 \n",
      "DRISHTI-GS      | glaucome:   70 | normal:   31 \n",
      "LAG             | glaucome: 1711 | normal: 3143 \n",
      "ORIGA           | glaucome:  168 | normal:  482 \n",
      "RIM-ONE         | glaucome:  172 | normal:  313 \n",
      "\n",
      "TOTALS\n",
      "glaucome : 2517\n",
      "normal   : 4278\n",
      "images totales : 6795\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "root = Path(\"data/glaucome\")\n",
    "exts = {\".jpg\", \".jpeg\", \".png\", \".tif\", \".tiff\", \".bmp\", \".gif\"}\n",
    "\n",
    "# stats[dataset][label]\n",
    "stats = defaultdict(lambda: defaultdict(int))\n",
    "unknown = defaultdict(int)\n",
    "\n",
    "for p in root.rglob(\"*\"):\n",
    "    if not p.is_file() or p.suffix.lower() not in exts:\n",
    "        continue\n",
    "\n",
    "    parts = [x.lower() for x in p.parts]\n",
    "\n",
    "    # Dataset = premier dossier après data/glaucome\n",
    "    try:\n",
    "        dataset = p.relative_to(root).parts[0]\n",
    "    except Exception:\n",
    "        dataset = \"UNKNOWN\"\n",
    "\n",
    "    # Label STRICTEMENT par dossier\n",
    "    if \"glaucoma\" in parts:\n",
    "        label = \"glaucome\"\n",
    "    elif \"normal\" in parts:\n",
    "        label = \"normal\"\n",
    "    else:\n",
    "        label = \"inconnu\"\n",
    "\n",
    "    if label == \"inconnu\":\n",
    "        unknown[dataset] += 1\n",
    "    else:\n",
    "        stats[dataset][label] += 1\n",
    "\n",
    "\n",
    "# ----------- RAPPORT -----------\n",
    "print(\"RAPPORT GLAUCOME (structure-based)\\n\")\n",
    "\n",
    "total_g = total_n  = 0\n",
    "\n",
    "for dataset in sorted(set(list(stats.keys()) + list(unknown.keys()))):\n",
    "    g = stats[dataset].get(\"glaucome\", 0)\n",
    "    n = stats[dataset].get(\"normal\", 0)\n",
    "    u = unknown.get(dataset, 0)\n",
    "\n",
    "    print(f\"{dataset:<15} | glaucome: {g:4d} | normal: {n:4d} \")\n",
    "\n",
    "    total_g += g\n",
    "    total_n += n\n",
    "\n",
    "print(\"\\nTOTALS\")\n",
    "print(\"glaucome :\", total_g)\n",
    "print(\"normal   :\", total_n)\n",
    "print(\"images totales :\", total_g + total_n )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73fafcf",
   "metadata": {},
   "source": [
    "compte le nombre d'image que j'ai pour le diabete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dc6fa88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-diabete: 25810\n",
      "diabete: 9316\n",
      "total: 35126\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "csv_path = Path(\"data/diabete/diabetic-retinopathy-detection/trainLabels.csv/trainLabels.csv\")\n",
    "\n",
    "normal_diabete = 0\n",
    "diabete = 0\n",
    "\n",
    "with csv_path.open(newline=\"\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        level = int(row[\"level\"])\n",
    "        if level == 0:\n",
    "            normal_diabete += 1\n",
    "        else:\n",
    "            diabete += 1\n",
    "\n",
    "print(\"non-diabete:\", normal_diabete)\n",
    "print(\"diabete:\", diabete)\n",
    "print(\"total:\", normal_diabete + diabete)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2977d68e",
   "metadata": {},
   "source": [
    "compte le nombre d'image mda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78a5d1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMD train : 394\n",
      "AMD valid : 100\n",
      "Total AMD : 494\n",
      "Normal train : 400\n",
      "Normal valid : 100\n",
      "Total normal : 500\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "train_amd = len(os.listdir(r\"data\\mda\\AMDNet23 Fundus Image Dataset for  Age-Related Macular Degeneration Disease Detection\\AMDNet23 Fundus Image Dataset for  Age-Related Macular Degeneration Disease Detection\\AMDNet23 Dataset\\train\\amd\"))\n",
    "valid_amd = len(os.listdir(r\"data\\mda\\AMDNet23 Fundus Image Dataset for  Age-Related Macular Degeneration Disease Detection\\AMDNet23 Fundus Image Dataset for  Age-Related Macular Degeneration Disease Detection\\AMDNet23 Dataset\\valid\\amd\"))\n",
    "\n",
    "train_normal = len(os.listdir(r\"data\\mda\\AMDNet23 Fundus Image Dataset for  Age-Related Macular Degeneration Disease Detection\\AMDNet23 Fundus Image Dataset for  Age-Related Macular Degeneration Disease Detection\\AMDNet23 Dataset\\train\\normal\"))\n",
    "valid_normal = len(os.listdir(r\"data\\mda\\AMDNet23 Fundus Image Dataset for  Age-Related Macular Degeneration Disease Detection\\AMDNet23 Fundus Image Dataset for  Age-Related Macular Degeneration Disease Detection\\AMDNet23 Dataset\\valid\\normal\"))\n",
    "\n",
    "AMDNet23_amd = train_amd + valid_amd\n",
    "AMDNet23_normal = train_normal + valid_normal\n",
    "\n",
    "print(\"AMD train :\", train_amd)\n",
    "print(\"AMD valid :\", valid_amd)\n",
    "print(\"Total AMD :\", AMDNet23_amd)\n",
    "print(\"Normal train :\", train_normal)\n",
    "print(\"Normal valid :\", valid_normal)\n",
    "print(\"Total normal :\", AMDNet23_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab6a87cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARMD : 783\n",
      "NORMAL : 957\n",
      "TOTAL : 1740\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base = r\"data\\mda\\Fundus\\Fundus\"\n",
    "\n",
    "Fundus_armd = len(os.listdir(os.path.join(base, \"ARMD\")))\n",
    "Fundus_normal = len(os.listdir(os.path.join(base, \"NORMAL\")))\n",
    "\n",
    "print(\"ARMD :\", Fundus_armd)\n",
    "print(\"NORMAL :\", Fundus_normal)\n",
    "print(\"TOTAL :\", Fundus_armd + Fundus_normal )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e18b4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal : 300\n",
      "AMD (14) : 46\n",
      "Total : 346\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base = r\"data\\mda\\fundus-dataset\"\n",
    "\n",
    "fundus_normal = len(os.listdir(os.path.join(base, \"00. Normal\")))\n",
    "fundus_amd = len(os.listdir(os.path.join(base, \"14. Age Related Macular Degeneration\")))\n",
    "\n",
    "print(\"Normal :\", fundus_normal)\n",
    "print(\"AMD (14) :\", fundus_amd)\n",
    "print(\"Total :\", fundus_normal + fundus_amd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "586fb2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal : 1028\n",
      "AMD : 532\n",
      "Total : 1560\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "labels_path = r\"data\\mda\\hyamd-high-resolution-fundus-image-dataset-for-age-related-macular-degeneration-amd-diagnosis-1.0.0\\hyamd-high-resolution-fundus-image-dataset-for-age-related-macular-degeneration-amd-diagnosis-1.0.0\\labels\\labels.csv\"\n",
    "\n",
    "df = pd.read_csv(labels_path)\n",
    "\n",
    "# 0 = non‑malade, 1/2 = malade\n",
    "hyamd_normal = (df[\"AMD\"] == 0).sum()\n",
    "hyamd_amd = (df[\"AMD\"] > 0).sum()\n",
    "\n",
    "print(\"Normal :\", hyamd_normal)\n",
    "print(\"AMD :\", hyamd_amd)\n",
    "print(\"Total :\", hyamd_normal + hyamd_amd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c73ad372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMD (A): 266\n",
      "Normal: 6126\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = r\"data\\mda\\ODIR-5K\\full_df.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "\n",
    "ODIR_amd = df[\"labels\"].astype(str).str.contains(r\"\\bA\\b\", regex=True).sum()\n",
    "ODIR_normal = len(df) - ODIR_amd\n",
    "print(\"AMD (A):\", ODIR_amd)\n",
    "print(\"Normal:\", ODIR_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a481536d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Somme malade mda : 2075\n",
      "Somme normal mda : 8611\n"
     ]
    }
   ],
   "source": [
    "total_malade = ( AMDNet23_amd + Fundus_armd + hyamd_amd + ODIR_amd)\n",
    "total_normal = ( AMDNet23_normal + Fundus_normal + hyamd_normal + ODIR_normal)\n",
    "print(\"Somme malade mda :\", total_malade)\n",
    "print(\"Somme normal mda :\", total_normal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e9bc7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal: 4278\n",
      "glaucoma: 2517\n",
      "non-diabete: 25810\n",
      "diabete: 9316\n",
      "Somme malade mda : 2075\n",
      "Somme normal mda : 8611\n",
      "\n",
      "total malade:  13908\n"
     ]
    }
   ],
   "source": [
    "print(\"normal:\", total_n)\n",
    "print(\"glaucoma:\", total_g)\n",
    "\n",
    "print(\"non-diabete:\", normal_diabete)\n",
    "print(\"diabete:\", diabete)\n",
    "\n",
    "print(\"Somme malade mda :\", total_malade)\n",
    "print(\"Somme normal mda :\", total_normal)\n",
    "\n",
    "print(\"\\ntotal malade: \", total_g + diabete  + total_malade )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57781c3a",
   "metadata": {},
   "source": [
    "pour hyamd certaines data sont absentes par exemple 002456631_D_2 est dans le csv mais n'existe pas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b420865b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: data\\glaucome\\ACRIMA -> 705\n",
      "OK: data\\glaucome\\DRISHTI-GS\\DRISHTI-GS\\Training\\glaucoma -> 32\n",
      "OK: data\\glaucome\\DRISHTI-GS\\DRISHTI-GS\\Testing\\glaucoma -> 38\n",
      "OK: data\\glaucome\\LAG\\LAG\\Training\\glaucoma -> 1369\n",
      "OK: data\\glaucome\\LAG\\LAG\\Testing\\glaucoma -> 342\n",
      "OK: data\\glaucome\\ORIGA\\ORIGA\\Training\\glaucoma -> 134\n",
      "OK: data\\glaucome\\ORIGA\\ORIGA\\Testing\\glaucoma -> 34\n",
      "OK: data\\glaucome\\RIM-ONE\\RIM-ONE\\NOT PARTITIONED\\glaucoma -> 172\n",
      "GLAUCOME uniques : 2517\n",
      "OK: data\\mda\\AMDNet23 Fundus Image Dataset for  Age-Related Macular Degeneration Disease Detection\\AMDNet23 Fundus Image Dataset for  Age-Related Macular Degeneration Disease Detection\\AMDNet23 Dataset\\train\\amd -> 394\n",
      "OK: data\\mda\\AMDNet23 Fundus Image Dataset for  Age-Related Macular Degeneration Disease Detection\\AMDNet23 Fundus Image Dataset for  Age-Related Macular Degeneration Disease Detection\\AMDNet23 Dataset\\valid\\amd -> 100\n",
      "OK: data\\mda\\Fundus\\Fundus\\ARMD -> 783\n",
      "OK: data\\mda\\fundus-dataset\\14. Age Related Macular Degeneration -> 46\n",
      "Manquants: 117\n",
      "['002456631_D_2', '002456631_L_5', '013035141_R_2', '021235653_R_4', '024056406_L_4', '055118813_L_2', '056498081_R_2', '060505439_L_3', '076550374_L_2', '083843679_L_2', '100881046_L_6', '100881046_R_7', '109536204_L_10', '115647280_R_4', '124162548_L_9', '125032178_R_2', '128300828_L_4', '169629416_R_5', '171688161_R_3', '186927674_L_4']\n",
      "HYAMD AMD attendues: 532\n",
      "HYAMD AMD ajoutées: 415\n",
      "HYAMD manquantes (labels sans fichier): 117\n",
      "ODIR AMD: 532\n",
      "DIABÈTE sélectionnées : 2500\n",
      "OK: data\\mda\\fundus-dataset\\00. Normal -> 300\n",
      "OK: data\\mda\\Fundus\\Fundus\\NORMAL -> 957\n",
      "NORMAUX sélectionnés : 2500\n",
      "\n",
      "CSV écrit : data\\dataset_selection.csv\n",
      "label\n",
      "glaucome    2517\n",
      "diabete     2500\n",
      "normaux     2484\n",
      "mda         2046\n",
      "Name: count, dtype: int64\n",
      "TOTAL : 9547\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# -----------------------\n",
    "# ROOTS\n",
    "# -----------------------\n",
    "root = Path(\"data\")\n",
    "mda_root = root / \"mda\"\n",
    "glaucome_root = root / \"glaucome\"\n",
    "dr_root = root / \"diabete\" / \"diabetic-retinopathy-detection\"\n",
    "\n",
    "exts = {\".jpg\", \".jpeg\", \".png\", \".tif\", \".tiff\", \".bmp\", \".gif\"}\n",
    "\n",
    "# -----------------------\n",
    "# UTILS\n",
    "# -----------------------\n",
    "def list_images(folder: Path):\n",
    "    folder = Path(folder)\n",
    "    if not folder.exists():\n",
    "        print(\"MANQUANT:\", folder)\n",
    "        return []\n",
    "    imgs = [p for p in folder.rglob(\"*\") if p.is_file() and p.suffix.lower() in exts]\n",
    "    print(\"OK:\", folder, \"->\", len(imgs))\n",
    "    return imgs\n",
    "\n",
    "def uniq_existing(paths):\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for p in paths:\n",
    "        p = Path(p)\n",
    "        if not p.exists():\n",
    "            continue\n",
    "        rp = p.resolve()\n",
    "        if rp in seen:\n",
    "            continue\n",
    "        seen.add(rp)\n",
    "        out.append(rp)\n",
    "    return out\n",
    "\n",
    "# =========================================================\n",
    "# 1) GLAUCOME (glaucoma uniquement)\n",
    "# =========================================================\n",
    "glaucome = []\n",
    "\n",
    "# ACRIMA\n",
    "tmp = list_images(glaucome_root / \"ACRIMA\")\n",
    "glaucome += [p for p in tmp if \"glaucoma\" in [x.lower() for x in p.parts]]\n",
    "\n",
    "glaucome += list_images(glaucome_root / \"DRISHTI-GS\" / \"DRISHTI-GS\" / \"Training\" / \"glaucoma\")\n",
    "glaucome += list_images(glaucome_root / \"DRISHTI-GS\" / \"DRISHTI-GS\" / \"Testing\" / \"glaucoma\")\n",
    "glaucome += list_images(glaucome_root / \"LAG\" / \"LAG\" / \"Training\" / \"glaucoma\")\n",
    "glaucome += list_images(glaucome_root / \"LAG\" / \"LAG\" / \"Testing\" / \"glaucoma\")\n",
    "glaucome += list_images(glaucome_root / \"ORIGA\" / \"ORIGA\" / \"Training\" / \"glaucoma\")\n",
    "glaucome += list_images(glaucome_root / \"ORIGA\" / \"ORIGA\" / \"Testing\" / \"glaucoma\")\n",
    "glaucome += list_images(glaucome_root / \"RIM-ONE\" / \"RIM-ONE\" / \"NOT PARTITIONED\" / \"glaucoma\")\n",
    "\n",
    "glaucome = uniq_existing(glaucome)\n",
    "print(\"GLAUCOME uniques :\", len(glaucome))\n",
    "\n",
    "# =========================================================\n",
    "# 2) MDA / AMD \n",
    "# =========================================================\n",
    "mda = []\n",
    "\n",
    "# ---------- AMDNet23 ----------\n",
    "mda += list_images(mda_root / \"AMDNet23 Fundus Image Dataset for  Age-Related Macular Degeneration Disease Detection\" / \"AMDNet23 Fundus Image Dataset for  Age-Related Macular Degeneration Disease Detection\" / \"AMDNet23 Dataset\" / \"train\" / \"amd\")\n",
    "mda += list_images(mda_root / \"AMDNet23 Fundus Image Dataset for  Age-Related Macular Degeneration Disease Detection\" / \"AMDNet23 Fundus Image Dataset for  Age-Related Macular Degeneration Disease Detection\" / \"AMDNet23 Dataset\" / \"valid\" / \"amd\")\n",
    "\n",
    "# ---------- Fundus ----------\n",
    "mda += list_images(mda_root / \"Fundus\" / \"Fundus\" / \"ARMD\")\n",
    "\n",
    "# ---------- fundus ----------\n",
    "mda += list_images(mda_root / \"fundus-dataset\" / \"14. Age Related Macular Degeneration\")\n",
    "\n",
    "# -------- HYAMD --------\n",
    "hyamd_root = mda_root / \"hyamd-high-resolution-fundus-image-dataset-for-age-related-macular-degeneration-amd-diagnosis-1.0.0\" / \\\n",
    "            \"hyamd-high-resolution-fundus-image-dataset-for-age-related-macular-degeneration-amd-diagnosis-1.0.0\"\n",
    "labels_hyamd = hyamd_root / \"labels\" / \"labels.csv\"\n",
    "hyamd_images = hyamd_root / \"Images\"\n",
    "\n",
    "df_hy = pd.read_csv(labels_hyamd)\n",
    "hy_amd = df_hy[df_hy[\"AMD\"] > 0][\"image_id\"].astype(str).tolist()\n",
    "\n",
    "# index des fichiers par stem normalisé\n",
    "files = [p for p in hyamd_images.iterdir() if p.is_file()]\n",
    "index = {}\n",
    "for p in files:\n",
    "    key = p.stem.rstrip(\"_\")\n",
    "    index.setdefault(key, []).append(p)\n",
    "\n",
    "hyamd_paths = []\n",
    "missing = 0\n",
    "for img_id in hy_amd:\n",
    "    if img_id in index:\n",
    "        hyamd_paths.extend(index[img_id])\n",
    "    else:\n",
    "        missing += 1\n",
    "\n",
    "# dedup\n",
    "hyamd_paths = list({p.resolve() for p in hyamd_paths})\n",
    "# Après construction de index + hy_amd\n",
    "missing_ids = [img_id for img_id in hy_amd if img_id not in index]\n",
    "print(\"Manquants:\", len(missing_ids))\n",
    "print(missing_ids[:20])\n",
    "\n",
    "print(\"HYAMD AMD attendues:\", len(hy_amd))\n",
    "print(\"HYAMD AMD ajoutées:\", len(hyamd_paths))\n",
    "print(\"HYAMD manquantes (labels sans fichier):\", missing)\n",
    "\n",
    "mda += hyamd_paths\n",
    "\n",
    "\n",
    "# ---------- ODIR ----------\n",
    "labels_odir = mda_root / \"ODIR-5K\"  / \"full_df.csv\"\n",
    "df_odir = pd.read_csv(labels_odir)\n",
    "\n",
    "odir_img_dir = mda_root / \"ODIR-5K\" / \"ODIR-5K\" / \"Training Images\"  # ajuste si besoin\n",
    "odir_amd_ids = df_odir[df_odir[\"labels\"].astype(str).str.contains(r\"\\bA\\b\", regex=True)][\"ID\"].tolist()\n",
    "\n",
    "odir_paths = []\n",
    "for id_ in odir_amd_ids:\n",
    "    odir_paths += [odir_img_dir / f\"{id_}_left.jpg\", odir_img_dir / f\"{id_}_right.jpg\"]\n",
    "\n",
    "odir_paths = [p for p in odir_paths if p.exists()]\n",
    "print(\"ODIR AMD:\", len(odir_paths))\n",
    "\n",
    "mda += odir_paths\n",
    "\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 3) DIABÈTE (2500)\n",
    "# =========================================================\n",
    "labels_csv = dr_root / \"trainLabels.csv\" / \"trainLabels.csv\"\n",
    "images_dir = dr_root / \"train\" / \"train\"\n",
    "\n",
    "df_dr = pd.read_csv(labels_csv)\n",
    "diab_ids = df_dr[df_dr[\"level\"] > 0][\"image\"].tolist()\n",
    "\n",
    "diab_paths = [\n",
    "    images_dir / f\"{img_id}.jpeg\"\n",
    "    for img_id in diab_ids\n",
    "    if (images_dir / f\"{img_id}.jpeg\").exists()\n",
    "]\n",
    "\n",
    "random.shuffle(diab_paths)\n",
    "diab_2500 = uniq_existing(diab_paths[:2500])\n",
    "\n",
    "print(\"DIABÈTE sélectionnées :\", len(diab_2500))\n",
    "\n",
    "# =========================================================\n",
    "# 4) NORMAUX (2500)\n",
    "# =========================================================\n",
    "normaux = []\n",
    "normaux += list_images(mda_root / \"fundus-dataset\" / \"00. Normal\")\n",
    "normaux += list_images(mda_root / \"Fundus\" / \"Fundus\" / \"NORMAL\")\n",
    "\n",
    "hy_norm = df_hy[df_hy[\"AMD\"] == 0][\"image_id\"].tolist()\n",
    "normaux += [hyamd_images / f for f in hy_norm]\n",
    "\n",
    "odir_norm_ids = df_odir[~df_odir[\"labels\"].astype(str).str.contains(r\"\\bA\\b\", regex=True)][\"ID\"].tolist()\n",
    "for id_ in odir_norm_ids:\n",
    "    normaux += [odir_img_dir / f\"{id_}_left.jpg\", odir_img_dir / f\"{id_}_right.jpg\"]\n",
    "\n",
    "normaux = uniq_existing(normaux)\n",
    "random.shuffle(normaux)\n",
    "normaux = normaux[:2500]\n",
    "\n",
    "print(\"NORMAUX sélectionnés :\", len(normaux))\n",
    "\n",
    "# =========================================================\n",
    "# 5) CSV FINAL\n",
    "# =========================================================\n",
    "rows = []\n",
    "rows += [(str(p), \"glaucome\") for p in glaucome]\n",
    "rows += [(str(p), \"mda\") for p in mda]\n",
    "rows += [(str(p), \"diabete\") for p in diab_2500]\n",
    "rows += [(str(p), \"normaux\") for p in normaux]\n",
    "\n",
    "df_out = pd.DataFrame(rows, columns=[\"path\", \"label\"])\n",
    "df_out[\"path\"] = df_out[\"path\"].apply(lambda p: str(Path(p).resolve()))\n",
    "df_out = df_out.drop_duplicates(subset=[\"path\"])\n",
    "\n",
    "out = root / \"dataset_selection.csv\"\n",
    "df_out.to_csv(out, index=False)\n",
    "\n",
    "print(\"\\nCSV écrit :\", out)\n",
    "print(df_out[\"label\"].value_counts())\n",
    "print(\"TOTAL :\", len(df_out))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdatatp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
